---
title: 'Text as Linguistic Data'
subtitle: 'Corpus analysis with polmineR - An Overview'
author: "Andreas Blaette"
date: "16. Juli 2018"
output:
  slidy_presentation:
    footer: Copyright (c) 2018, Andreas Blaette
  ioslides_presentation: default
  beamer_presentation: default
editor_options: 
  chunk_output_type: console
---


## Why do corpus analysis with R?

- R as a lingua franca of social sciences
- interactivity
- friendly user community
- RStudio as IDE
- dynamic and ongoing development of R and RStudio


## Aims of polmineR

- Open Source
- Portability (Usage with Windows, macOS, Linux)
- Interactivity
- Reproducibility and validity (through full text displays)
- Performance
- User-friendly (documentation)
----

## Installation

### System requirements

- Windows, macOS, Linux
- (if possible) more than 4GB RAM
- optional: multiple processor cores, SSD


### Installing polmineR: Windows

#### Installing the CRAN relase

```{r, eval = FALSE}
install.packages("polmineR")
```

#### Installing the development version from GitHub

```{r, eval = FALSE}
devtools::install_github("PolMine/polmineR", ref = "dev")
```

----

## Post-installation Steps

```{r, eval = FALSE}
library(polmineR)
```

### Environment Variable CORPUS_REGISTRY

The environment variable'CORPUS_REGISTRY' can be set like this:

```{r, eval = FALSE}
Sys.getenv("CORPUS_REGISTRY")
Sys.setenv(CORPUS_REGISTRY = "/var/local/cwb/registry")
```

Persistent definition is possible via the following files:
- .Renviron
- Startup data in /etc/R/


### Installation of Corpora

Via a ['drat'-Repository](https://cran.r-project.org/web/packages/drat/vignettes/DratFAQ.html) of the PolMine project at GitHub data packages with corpora are available. Normally they contain only small test data. The actual corpus must then be loaded subsequently. The GermaParl package is used to describe how to install these packages.

```{r, eval = FALSE}
install.packages("drat")
drat::addRepo("polmine")
install.packages("GermaParl")
```

Load the corpus like this:

```{r, eval = FALSE}
library(GermaParl)
germaparl_download_corpus()
```

After that, activate the corpus of the GermaParl package via

```{r, eval = FALSE}
library(polmineR)
use("GermaParl")
```

----

### polmineR - Quick-start (work with Corpora and CQP)

Display of Concordances / Keyword-in-Context (KWIC) ...

```{r, eval = FALSE}
kwic("GERMAPARL", "Islam", meta = "year")
kwic("GERMAPARL", '[pos = "ADJA"] "Integration"', cqp = TRUE, meta = "speaker")
```

Counting word frequencies...

```{r, eval = FALSE}
cnt <- count("GERMAPARL", p_attribute = "word")
```

Working with complex queries (CQP Syntax)...

```{r, eval = FALSE}
count("GERMAPARL", query = '[pos = "ADJA"] "Integration"')
```

Distribution of a search query ...

```{r, eval = FALSE}
d <- dispersion("GERMAPARL", query = "Aussiedler", s_attribute = "year")
```

----

### polmineR - Quick-start (working with subcorpora / "partitions")

Create a Partition ...

```{r, eval = FALSE}
merkel <- partition("GERMAPARL", speaker = "Angela Merkel", date = "2005-11-30", type = "plpr")
```

Display the full text ...

```{r, eval = FALSE}
read(regerklaerung)
```

Show Concordances ...

```{r, eval = FALSE}
bt2002 <- partition("GERMAPARL", year = "2002", interjection = FALSE)
kwic(bt2002, "Islam", meta = "year")
kwic(bt2002, "Islam", meta = c("year", "speaker"))
kwic(bt2002, "Islam", meta = c("year", "speaker", "party"))
kwic(bt2002, "Islam", meta = c("year", "speaker", "party"), left = 30, right = 30)
```

Frequency counting

```{r, eval = FALSE}
bt2002 <- partition("GERMAPARL", year = "2002", p_attribute = "word", type = "plpr")
view(bt2002)
```


```{r, eval = FALSE}
M <- enrich(merkel, p_attribute = c("word", "pos"))
view(M)
```

----

### A small visualization scenario

```{r, eval = TRUE}
library(RColorBrewer)
library(polmineR)
use("GermaParl", verbose = FALSE)
```

```{r, eval = TRUE}
M <- partition(
  "GERMAPARL", speaker = "Angela Merkel", date = "2005-11-30",
  interjection = "FALSE", p_attribute = c("word", "pos"), verbose = FALSE
  )
nouns <- subset(M, pos == "NN")
nouns <- sort(nouns, "count")
```

----

```{r}
dotplot(nouns, col = "count", n = 25)
```


----

```{r, eval = TRUE}
library(wordcloud)
wordcloud(
  words = nouns@stat[["word"]][1:50],
  freq = nouns@stat[["count"]][1:50]/2,
  colors = brewer.pal(8,"Dark2")
  )
```

----


## Create Partitions


### One important distinction

- s-Attribute (parameter s_attributes)
- p-Attribute (parameter p_attributes)


### Exploration of a corpus

Find available p-Attributes

```{r, eval = TRUE}
p_attributes("GERMAPARL")
```

Find available s-Attributes

```{r, eval = FALSE}
s_attributes("GERMAPARL")
```

Determining the values of an s-attribute

```{r, eval = TRUE}
speakers <- s_attributes("GERMAPARL", "speaker")
head(speakers)
```

----


#### Partitioning


```{r, eval = FALSE}
schroeder <- partition("GERMAPARL", speaker = "Gerhard Schröder")
bk <- partition("GERMAPARL", speaker = c("Gerhard Schröder", "Angela Merkel"))
bk <- partition("GERMAPARL", speaker = c("Gerhard Schröder", "Angela Merkel"), lp=c("14", "15", "16"))
```

----
Short introduction to the world of regular expressions
--------------------------------------------------

**Character classes: **
. any character
\\d number

** Quantizers **
+ at least once
* none or any number of times
{} certain number

** Miscellaneous **
Alternatives in brackets
alternative characters in square brackets 

```{r, eval = FALSE}
schroederPost911 <- partition(
  "GERMAPARL", speaker = "Gerhard Schröder",
  date = c("2001-(09|10|11|12)-.*"), regex = TRUE
  )
sAttributes(schroederPost911, "date")
```

Bundle Partitions!
---------------------

```{r, eval = FALSE}
schroeder <- partition_bundle(
  schroederPost911,
  sAttribute = s_attributes(schroederPost911, "date"),
  type = "plpr"
)
summary(schroeder)
read(schroeder, meta = "speaker_date")
label(schroeder, meta = "speaker_date")
1read(schroeder[[8]], meta = "speaker_date")
```


An advanced scenario
------------------------------

```{r, eval = FALSE}
library(chron)
library(magrittr)
days <- s_attributes("GERMAPARL", "date")
aftermath <- seq.dates(from = "11/09/2001", "11/03/2002", by = "days") %>%
  as.Date(format="%Y-%m-%d") %>%
  as.character
sessionsAftermath <- days[days %in% aftermath]
foo <- partition("GERMAPARL", date =sessionsAftermath, p_attribute="word")
view(foo)
```

Some additional possibilities

----------------------------
- zoom into partitions
- session settings

```{r, eval = FALSE}
session
corpus(session)
corpus(session) <- "BT"
```


Frequency Counting
=================

## count()

```{r, eval = FALSE}
btByYears <- partition_bundle(
  "BT",
  def = list(speaker_type="speech"),
  var=list(speaker_year=NULL)
  )
islam <- count(
  btByYears,
  query=c('Islam', 'Muslime', 'Terror'),
  pAttribute="word", mc=FALSE
  )
islam2 <- as.data.frame(islam)[, c(2:ncol(islam))]
rownames(islam2) <- islam[["partition"]]
library(bubblegraph)
linechart(as.data.frame(t(islam2)))
```


```{r, eval = FALSE}
mig <- count(
  btByYears,
  query=c('"Asyl.*"', '"Flüchtling.*"', '".*[aA]ussiedler.*"', '"Übersiedler.*"', '"Gastarbeiter.*"', '"Vertriebene.*"', '"Menschen" "mit" "Migrationshintergrund"'),
  pAttribute="word", mc=FALSE
  )
mig2 <- as.data.frame(mig)[, c(2:ncol(mig))]
rownames(mig2) <- mig[["partition"]]
library(bubblegraph)
linechart(as.data.frame(t(mig2)))

```


### Frequency counting with CQP syntax

## Using the CQP syntax

Basics:
- Triggering p attributes
- quantizers 
- place markers

```{r, eval = FALSE}
sttsTagsetInfo <- "http://www.ims.uni-stuttgart.de/forschung/ressourcen/lexika/TagSets/stts-table.html"
browseURL(sttsTagsetInfo)
```


http://cwb.sourceforge.net/files/CQP_Tutorial/
http://cwb.sourceforge.net/files/CQP_Tutorial.pdf
http://www.ims.uni-stuttgart.de/forschung/projekte/CorpusWorkbench/CQPTutorial/cqp-tutorial.2up.pdf



```{r, eval = FALSE}
btByYear <- partitionBundle(
  "BT",
  def=list(speaker_type="speech"),
  var=list(speaker_year=as.character(c(1998:2007)))
  )

mig <- count(
  btByYear,
  query=c('"Asyl.*"', '"Flüchtling.*"', '".*[aA]ussiedler.*"', '"Übersiedler.*"', '"Gastarbeiter.*"', '"Vertriebene.*"'),
  pAttribute="word", mc=FALSE
  )
mig2 <- as.data.frame(mig)[, c(2:ncol(mig))]
rownames(mig2) <- mig[["partition"]]
library(bubblegraph)
linechart(as.data.frame(t(mig2)))
```


frequencies()
-------------

```{r, eval = FALSE}
foo <- frequencies(bt, query='"[mM]ultikult.*"', pAttribute=NULL)
```

Exercise: Differences between political parties ...

```{r, eval = FALSE}
csu <- partition(list(speaker_party=".*CSU.*"), regex=TRUE)
```

Concordances
============

```{r, eval = FALSE}
kwic("GERMAPARL", '"Krieg" []{1,5} "Terror"', meta = "speaker")
kwic(bt, '"Krieg" "gegen" "den" "Terror"', meta=c("speaker_date", "speaker_name"))
```

```{r, eval = FALSE}
foo <- frequencies(bt, '"()"')

Bkwic(bt, '"Krieg" "gegen" []{0,1} [pos="NN"]', meta=c("speaker_date", "speaker_party"))
```

Help inspection ...

And an example: prevention in social policy


##### Collocation analyses

```{r, eval = FALSE}
bt <- partition("BT", list(speaker_year="2006"), regex=TRUE)
islam <- context(bt, "Islam", pAttribute="word")
islam <- context(bt, '"Islam.*"', pAttribute=c("word", "pos"))
view(islam)
islam2 <- subset(islam, pos %in% c("NN", "ADJA"))
view(islam2)
wordcloud(
  words=islam2@stat[["word"]][1:50],
  freq=islam2@stat[["ll"]][1:50]/2,
  colors=brewer.pal(8,"Dark2")
  )
dotplot(islam2, col="ll", 25)
```

Going further: t-test, PMI, log-likelihood implemented as a test procedure

** Note: **
- Dependency of the statistical test values on the corpus size
- no immediate comparability of the test values!
- qualitative validation


** Discussion: **
Which filters are appropriate?
Which thresholds are appropriate?
What is the appropriate context for political science questions?
----

#### Keyword analyses


What doesn't work...

```{r, eval = FALSE}
schroeder1 <- partition("GERMAPARL", speaker = "Gerhard Schröder", date = "2001-09-12", pAttribute = "word")
schroeder2 <- partition("GERMAPARL", speaker = "Gerhard Schröder", date="2001-09-19", pAttribute = "word")
schroeder3 <- partition("GERMAPARL", speaker = "Gerhard Schröder", date="2001-11-28", pAttribute = "word")

bt2001 <- partition("GERMAPARL", year = "2001", pAttribute = "word")

keyws1 <- features(schroeder1, bt2001)
keyws2 <- features(schroeder2, bt2001)
keyws3 <- features(schroeder3, bt2001)

view(keyws1)
view(keyws2)
view(keyws3)
```


The more, the better ...

```{r, eval = FALSE}
bt2002 <- partition("GERMAPARL", year = "2002", interjection = FALSE, pAttribute="word")
btBefore <- partition("GERMAPARL", year = 1996:2001, interjection = FALSE, pAttribute = "word")

keyws <- features(bt2002, btBefore)
view(keyws)
```


Exercise: Main topics of Schröder in the 15th legislative period?


Perspectives for text statistics
==============================

```{r, eval = FALSE}
merkel <- partition("BT", list(speaker_name=".*Merkel.*", speaker_type="speech"), regex=TRUE, pAttribute="word")
merkelSpeeches <- as.speeches(
  merkel, sAttributeDates="speaker_date", sAttributeNames="speaker_name",
  gap=500
  )
merkelSpeeches <- enrich(merkelSpeeches, pAttribute="word")
dtm <- as.DocumentTermMatrix(merkelSpeeches, col="count")
toDrop <- polmineR:::noise(dtm)
dtmTrimmed <- trim(dtm, termsToDrop=unique(unlist(toDrop)))
dtmTrimmed <- trim(dtmTrimmed, docsToDrop = names(which(slam::row_sums(dtmTrimmed) < 20)))

library(topicmodels)
tmodel <- LDA(
  dtmTrimmed, k=20, method = "Gibbs",
  control = list(burnin = 1000, iter = 50, keep = 50, verbose=TRUE)
)
View(terms(tmodel, k=20))
```


### What's actually happening?!

- S4 classes and their slots (structure analysis with str())
- Inheritance of methods, less to remember

```{r, eval = FALSE}
str(nounsOnly)
methods("partition"")
getMethod("subset", "textstat")
```


----

## Prospects: options

- Perl (regular expressions etc.)
- Python (NLTK, etc.)
- Java (Stanford NLP, mallet etc.)
- C++ (Performance)
